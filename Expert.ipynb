{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "from skimage.feature import match_template\n",
    "from skimage.feature import peak_local_max\n",
    "import cv2\n",
    "import MTM\n",
    "from MTM import matchTemplates, drawBoxesOnRGB\n",
    "from scipy import signal\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn based fast, normalized cross-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = imread('test_image_2.png')\n",
    "sample_g = rgb2gray(sample)\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,10))\n",
    "ax[0].imshow(sample)\n",
    "ax[1].imshow(sample_g,cmap='gray')\n",
    "ax[0].set_title('Colored Image',fontsize=15)\n",
    "ax[1].set_title('Grayscale Image',fontsize=15)\n",
    "plt.show()\n",
    "for i in os.listdir(\"ExpertTemplate\"):\n",
    "    template = imread(os.path.join(os.getcwd(),\"ExpertTemplate\",i))\n",
    "    template_g = rgb2gray(template)\n",
    "    sample_mt = match_template(sample_g, template_g)\n",
    "    fig, ax = plt.subplots(1,2,figsize=(10,10))\n",
    "    ax[0].imshow(sample_g,cmap='gray')\n",
    "    ax[1].imshow(sample_mt,cmap='gray')\n",
    "    ax[0].set_title('Grayscale',fontsize=15)\n",
    "    ax[1].set_title('Template Matching',fontsize=15);\n",
    "    fig, ax = plt.subplots(1,2,figsize=(10,10))\n",
    "    ax[0].imshow(sample)\n",
    "    ax[1].imshow(sample)\n",
    "    patch_width, patch_height = template_g.shape\n",
    "    for x, y in peak_local_max(sample_mt, threshold_abs=0.6):\n",
    "        rect = plt.Rectangle((y, x), patch_height, patch_width, color='r', \n",
    "                             fc='none')\n",
    "        ax[1].add_patch(rect)\n",
    "    ax[0].set_title('Colored Image',fontsize=15)\n",
    "    ax[1].set_title('Template Matched',fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB based feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('test_image_2.png',cv2.IMREAD_GRAYSCALE)\n",
    "for i in os.listdir(\"ExpertTemplate\"):\n",
    "    img2 = cv2.imread(os.path.join(os.getcwd(),\"ExpertTemplate\",i),cv2.IMREAD_GRAYSCALE)\n",
    "#     img2 = cv2.imread('template_image.png',cv2.IMREAD_GRAYSCALE)\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "    #cv.NORM_HAMMING method\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1,des2)\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:10],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.figure(figsize=(15, 12), dpi=80)\n",
    "    plt.imshow(img3),plt.show()\n",
    "    # cv.NORM_L2 method\n",
    "    bf2 = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf2.match(des1,des2)\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:10],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.figure(figsize=(15, 12), dpi=80)\n",
    "    plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT with BFMatcher based fature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('test_image_2.png',cv2.IMREAD_GRAYSCALE)\n",
    "for i in os.listdir(\"ExpertTemplate\"):\n",
    "    img2 = cv2.imread(os.path.join(os.getcwd(),\"ExpertTemplate\",i),cv2.IMREAD_GRAYSCALE)\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1,des2,k=2)\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append([m])\n",
    "    img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.figure(figsize=(15, 12), dpi=80)\n",
    "    plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT with FLANN based fature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('test_image_2.png',cv2.IMREAD_GRAYSCALE)\n",
    "for i in os.listdir(\"ExpertTemplate\"):\n",
    "    img2 = cv2.imread(os.path.join(os.getcwd(),\"ExpertTemplate\",i),cv2.IMREAD_GRAYSCALE)\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50) \n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "    matchesMask = [[0,0] for i in range(len(matches))]\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            matchesMask[i]=[1,0]\n",
    "    draw_params = dict(matchColor = (0,255,0),\n",
    "                       singlePointColor = (255,0,0),\n",
    "                       matchesMask = matchesMask,\n",
    "                       flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "    img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,matches,None,**draw_params)\n",
    "    plt.figure(figsize=(15, 12), dpi=80)\n",
    "    plt.imshow(img3,),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi scale template matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(\"ExpertTemplate\"):\n",
    "    template = cv2.imread(os.path.join(os.getcwd(),\"ExpertTemplate\",i),cv2.IMREAD_GRAYSCALE)\n",
    "    template = cv2.Canny(template, 50, 200)\n",
    "    (tH, tW) = template.shape[:2]\n",
    "    plt.imshow(template)\n",
    "    plt.show()\n",
    "    image = cv2.imread('test_image_2.png') \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    found = None\n",
    "    for scale in np.linspace(0.2, 1.0, 20)[::-1]:\n",
    "        resized = imutils.resize(gray, width = int(gray.shape[1] * scale))\n",
    "        r = gray.shape[1] / float(resized.shape[1])\n",
    "        if resized.shape[0] < tH or resized.shape[1] < tW:\n",
    "            break\n",
    "        edged = cv2.Canny(resized, 50, 200)\n",
    "        result = cv2.matchTemplate(edged, template, cv2.TM_CCOEFF)\n",
    "        (_, maxVal, _, maxLoc) = cv2.minMaxLoc(result)\n",
    "        clone = np.dstack([edged, edged, edged])\n",
    "        cv2.rectangle(clone, (maxLoc[0], maxLoc[1]),(maxLoc[0] + tW, maxLoc[1] + tH), (0, 0, 255), 2)\n",
    "        plt.imshow(clone)\n",
    "        plt.show()\n",
    "        if found is None or maxVal > found[0]:\n",
    "            found = (maxVal, maxLoc, r)\n",
    "    (_, maxLoc, r) = found\n",
    "    (startX, startY) = (int(maxLoc[0] * r), int(maxLoc[1] * r))\n",
    "    (endX, endY) = (int((maxLoc[0] + tW) * r), int((maxLoc[1] + tH) * r))\n",
    "    cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template matching with different opencv methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/anaconda3/envs/DataCreaterV1/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('test_image_2.png',0)\n",
    "img2 = img.copy()\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "for i in os.listdir(\"ExpertTemplate\"):\n",
    "    template = cv2.imread(os.path.join(os.getcwd(),\"ExpertTemplate\",i),cv2.IMREAD_GRAYSCALE)\n",
    "    w, h = template.shape[::-1]\n",
    "    for meth in methods:\n",
    "        img = img2.copy()\n",
    "        method = eval(meth)\n",
    "        res = cv2.matchTemplate(img,template,method)\n",
    "        fig, ax = plt.subplots(1,2,figsize=(20,20))\n",
    "        ax[0].imshow(img)\n",
    "        ax[1].imshow(img)\n",
    "        patch_width, patch_height = img2.shape\n",
    "        for x, y in peak_local_max(res, threshold_abs=0.6):\n",
    "            rect = plt.Rectangle((y, x), patch_height, patch_width, color='r', fc='none')\n",
    "            ax[1].add_patch(rect)\n",
    "        ax[0].set_title('Grayscale',fontsize=15)\n",
    "        ax[1].set_title('Template Matched',fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template matching using MTM package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test_image_2.png',0)\n",
    "for i in os.listdir(\"ExpertTemplate\"):\n",
    "    template = cv2.imread(os.path.join(os.getcwd(),\"ExpertTemplate\",i),cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    listTemplate = [('parle', template)]\n",
    "\n",
    "    threshold = 0.1\n",
    "\n",
    "    Hits = matchTemplates(listTemplate, img, score_threshold=threshold, method=cv2.TM_CCOEFF, maxOverlap=0)\n",
    "\n",
    "    Overlay = drawBoxesOnRGB(img, Hits, showLabel=True)\n",
    "    plt.imshow(Overlay)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    Hits2 = matchTemplates(listTemplate, img, score_threshold=threshold, method=cv2.TM_CCOEFF_NORMED, maxOverlap=0)\n",
    "\n",
    "    Overlay2 = drawBoxesOnRGB(img, Hits2, showLabel=True)\n",
    "    plt.imshow(Overlay2)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    Hits3 = matchTemplates(listTemplate, img, score_threshold=threshold, method=cv2.TM_CCORR, maxOverlap=0)\n",
    "\n",
    "    Overlay3 = drawBoxesOnRGB(img, Hits3, showLabel=True)\n",
    "    plt.imshow(Overlay3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    Hits4 = matchTemplates(listTemplate, img, score_threshold=threshold, method=cv2.TM_CCORR_NORMED, maxOverlap=0)\n",
    "\n",
    "    Overlay4 = drawBoxesOnRGB(img, Hits4, showLabel=True)\n",
    "    plt.imshow(Overlay4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    Hits6 = matchTemplates(listTemplate, img, score_threshold=threshold, method=cv2.TM_SQDIFF_NORMED, maxOverlap=0)\n",
    "\n",
    "    Overlay6 = drawBoxesOnRGB(img, Hits6, showLabel=True)\n",
    "    plt.imshow(Overlay6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy based correlation between image and template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test_image_2.png',0)\n",
    "for i in os.listdir(\"ExpertTemplate\"):\n",
    "    template = cv2.imread(os.path.join(os.getcwd(),\"ExpertTemplate\",i),cv2.IMREAD_GRAYSCALE)\n",
    "    corr = signal.correlate2d(img, template, boundary='symm', mode='same')\n",
    "    y, x = np.unravel_index(np.argmax(corr), corr.shape)\n",
    "    fig, (ax_orig, ax_template, ax_corr) = plt.subplots(3, 1,figsize=(6, 15))\n",
    "    ax_orig.imshow(img, cmap='gray')\n",
    "    ax_orig.set_title('Original')\n",
    "    ax_orig.set_axis_off()\n",
    "    ax_template.imshow(template, cmap='gray')\n",
    "    ax_template.set_title('Template')\n",
    "    ax_template.set_axis_off()\n",
    "    ax_corr.imshow(corr, cmap='gray')\n",
    "    ax_corr.set_title('Cross-correlation')\n",
    "    ax_corr.set_axis_off()\n",
    "    ax_orig.plot(x, y, 'ro')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
